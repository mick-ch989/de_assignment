version: "3.8"

services:

  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"

  kafka:
    image: wurstmeister/kafka
    container_name: kafka
    depends_on:
      - zookeeper
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
    ports:
      - "9092:9092"

  kafka-exporter:
    image: danielqsj/kafka-exporter
    container_name: kafka-exporter
    command:
      - "--kafka.server=kafka:9092"
    ports:
      - "9308:9308"
    depends_on:
      - kafka

  minio:
    image: minio/minio:latest
    container_name: minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    ports:
      - "9000:9000"  # S3 API
      - "9001:9001"  # Console UI
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  minio-client:
    image: minio/mc:latest
    container_name: minio-client
    entrypoint: >
      /bin/sh -c "
      sleep 5;
      /usr/bin/mc alias set myminio http://minio:9000 minioadmin minioadmin;
      /usr/bin/mc mb myminio/streaming-pipeline-output || true;
      /usr/bin/mc anonymous set download myminio/streaming-pipeline-output || true;
      exit 0;
      "
    depends_on:
      - minio

  spark-master:
    image: apache/spark-py:latest
    container_name: spark-master
    user: root
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master -h spark-master
    environment:
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_JAVA_OPT_1=-Dcom.sun.management.jmxremote=true
      - SPARK_JAVA_OPT_2=-Dcom.sun.management.jmxremote.port=7078
      - SPARK_JAVA_OPT_3=-Dcom.sun.management.jmxremote.rmi.port=7078
      - SPARK_JAVA_OPT_4=-Dcom.sun.management.jmxremote.authenticate=false
      - SPARK_JAVA_OPT_5=-Dcom.sun.management.jmxremote.ssl=false
      - SPARK_JAVA_OPT_6=-Dcom.sun.management.jmxremote.local.only=false
      - SPARK_JAVA_OPT_7=-Djava.rmi.server.hostname=spark-master
    ports:
      - "7077:7077"
      - "8080:8080"
      - "7078:7078"


  spark-worker-1:
    image: apache/spark-py:latest
    container_name: spark-worker-1
    user: root
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=1g
      - SPARK_WORKER_DIR=/tmp/spark-worker
      - SPARK_JAVA_OPT_1=-Dcom.sun.management.jmxremote=true
      - SPARK_JAVA_OPT_2=-Dcom.sun.management.jmxremote.port=7079
      - SPARK_JAVA_OPT_3=-Dcom.sun.management.jmxremote.rmi.port=7079
      - SPARK_JAVA_OPT_4=-Dcom.sun.management.jmxremote.authenticate=false
      - SPARK_JAVA_OPT_5=-Dcom.sun.management.jmxremote.ssl=false
      - SPARK_JAVA_OPT_6=-Dcom.sun.management.jmxremote.local.only=false
      - SPARK_JAVA_OPT_7=-Djava.rmi.server.hostname=spark-worker-1
    ports:
      - "7079:7079"
    depends_on:
      - spark-master
    deploy:
      resources:
        limits:
          cpus: "2.0"
          memory: 1200M


  spark-worker-2:
    image: apache/spark-py:latest
    container_name: spark-worker-2
    user: root
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=1g
      - SPARK_WORKER_DIR=/opt/spark/work
      - SPARK_JAVA_OPT_1=-Dcom.sun.management.jmxremote=true
      - SPARK_JAVA_OPT_2=-Dcom.sun.management.jmxremote.port=7080
      - SPARK_JAVA_OPT_3=-Dcom.sun.management.jmxremote.rmi.port=7080
      - SPARK_JAVA_OPT_4=-Dcom.sun.management.jmxremote.authenticate=false
      - SPARK_JAVA_OPT_5=-Dcom.sun.management.jmxremote.ssl=false
      - SPARK_JAVA_OPT_6=-Dcom.sun.management.jmxremote.local.only=false
      - SPARK_JAVA_OPT_7=-Djava.rmi.server.hostname=spark-worker-2
    ports:
      - "7080:7080"
    depends_on:
      - spark-master
    deploy:
      resources:
        limits:
          cpus: "2.0"
          memory: 1200M

  spark-streaming:
    build:
      context: ./processing
    container_name: spark-streaming
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9093
      - KAFKA_TOPIC=input_events
      - KAFKA_STARTING_OFFSETS=earliest
      - CHECKPOINT_LOCATION=/tmp/streaming_checkpoint
      - OUTPUT_PATH=/tmp/streaming_output
      # Storage configuration - choose one:
      # Option 1: MinIO (local S3-compatible storage)
      - S3_BUCKET=streaming-pipeline-output
      - S3_PREFIX=streaming-output
      - S3_ENDPOINT=http://minio:9000
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      # Window and watermark configuration for faster testing
      - WINDOW_DURATION=30 seconds
      - WATERMARK_DELAY=1 minute
      # Option 2: AWS S3 (uncomment and comment MinIO settings above)
      # - S3_BUCKET=your-aws-bucket-name
      # - S3_PREFIX=streaming-output
      # - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      # - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
    depends_on:
      - spark-master
      - kafka
      - minio
    ports:
      - "4040:4040"  # Spark UI
    command: >
      /opt/spark/bin/spark-submit
      --master spark://spark-master:7077
      --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262
      --driver-memory 512m
      --executor-memory 512m
      --executor-cores 1
      --total-executor-cores 2
      --conf spark.sql.adaptive.enabled=true
      --conf spark.sql.streaming.checkpointLocation=/tmp/streaming_checkpoint
      --conf "spark.driver.extraJavaOptions=-Djava.net.preferIPv4Stack=true -Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.port=9999 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.local.only=false -Djava.rmi.server.hostname=spark-streaming"
      --conf "spark.executor.extraJavaOptions=-Djava.net.preferIPv4Stack=true"
      --conf spark.sql.shuffle.partitions=4
      /opt/spark_streaming_job.py


  spark-master-exporter:
    image: bitnami/jmx-exporter:latest
    container_name: spark-master-exporter
    entrypoint: ["java", "-jar", "/opt/bitnami/jmx-exporter/jmx_prometheus_standalone.jar"]
    command:
      - "5556"
      - "/config/config.yml"
    ports:
      - "9101:5556"
    volumes:
      - ./monitoring/jmx/spark-master.yml:/config/config.yml
    depends_on:
      - spark-master

  spark-worker-1-exporter:
    image: bitnami/jmx-exporter:latest
    container_name: spark-worker-1-exporter
    entrypoint: ["java", "-jar", "/opt/bitnami/jmx-exporter/jmx_prometheus_standalone.jar"]
    command:
      - "5556"
      - "/config/config.yml"
    ports:
      - "9102:5556"
    volumes:
      - ./monitoring/jmx/spark-worker-1.yml:/config/config.yml
    depends_on:
      - spark-worker-1

  spark-worker-2-exporter:
    image: bitnami/jmx-exporter:latest
    container_name: spark-worker-2-exporter
    entrypoint: ["java", "-jar", "/opt/bitnami/jmx-exporter/jmx_prometheus_standalone.jar"]
    command:
      - "5556"
      - "/config/config.yml"
    ports:
      - "9103:5556"
    volumes:
      - ./monitoring/jmx/spark-worker-2.yml:/config/config.yml
    depends_on:
      - spark-worker-2

  spark-streaming-exporter:
    image: bitnami/jmx-exporter:latest
    container_name: spark-streaming-exporter
    entrypoint: ["java", "-jar", "/opt/bitnami/jmx-exporter/jmx_prometheus_standalone.jar"]
    command:
      - "5556"
      - "/config/config.yml"
    ports:
      - "9104:5556"
    volumes:
      - ./monitoring/jmx/spark-streaming.yml:/config/config.yml
    depends_on:
      - spark-streaming

  prometheus:
    image: prom/prometheus
    container_name: prometheus
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
    depends_on:
      - kafka-exporter
      - spark-master-exporter
      - spark-worker-1-exporter
      - spark-worker-2-exporter
      - spark-streaming-exporter


  grafana:
    image: grafana/grafana
    container_name: grafana
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    ports:
      - "3000:3000"
    volumes:
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    depends_on:
      - prometheus

volumes:
  minio_data:
